{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Unidecode in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.3.6)\n",
      "Requirement already satisfied: nltk in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (3.8.1)\n",
      "Requirement already satisfied: emoji in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.6.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.0.2)\n",
      "Requirement already satisfied: autocorrect in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.6.1)\n",
      "Collecting swifter\n",
      "  Downloading swifter-1.3.5.tar.gz (490 kB)\n",
      "     ---------------------------------------- 0.0/490.6 kB ? eta -:--:--\n",
      "     ------- ------------------------------ 102.4/490.6 kB 3.0 MB/s eta 0:00:01\n",
      "     -------------------------------- ----- 419.8/490.6 kB 5.3 MB/s eta 0:00:01\n",
      "     --------------------------------- ---- 430.1/490.6 kB 3.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- 490.6/490.6 kB 3.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: click in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (1.24.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: psutil>=5.6.6 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from swifter) (5.9.4)\n",
      "Collecting dask[dataframe]>=2.10.0\n",
      "  Downloading dask-2023.6.1-py3-none-any.whl (1.2 MB)\n",
      "     ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "     ---------------------------------------  1.2/1.2 MB 24.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.2/1.2 MB 18.7 MB/s eta 0:00:00\n",
      "Collecting ipywidgets>=7.0.0\n",
      "  Downloading ipywidgets-8.0.6-py3-none-any.whl (138 kB)\n",
      "     ---------------------------------------- 0.0/138.3 kB ? eta -:--:--\n",
      "     -------------------------------------- 138.3/138.3 kB 8.0 MB/s eta 0:00:00\n",
      "Collecting cloudpickle>=0.2.2\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: parso>0.4.0 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from swifter) (0.8.3)\n",
      "Collecting bleach>=3.1.1\n",
      "  Downloading bleach-6.0.0-py3-none-any.whl (162 kB)\n",
      "     ---------------------------------------- 0.0/162.5 kB ? eta -:--:--\n",
      "     ------------------------------------- 162.5/162.5 kB 10.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from bleach>=3.1.1->swifter) (1.16.0)\n",
      "Collecting webencodings\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Collecting partd>=1.2.0\n",
      "  Downloading partd-1.4.0-py3-none-any.whl (18 kB)\n",
      "Collecting fsspec>=2021.09.0\n",
      "  Downloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "     ---------------------------------------- 0.0/163.8 kB ? eta -:--:--\n",
      "     ------------------------------------- 163.8/163.8 kB 10.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from dask[dataframe]>=2.10.0->swifter) (22.0)\n",
      "Collecting toolz>=0.10.0\n",
      "  Downloading toolz-0.12.0-py3-none-any.whl (55 kB)\n",
      "     ---------------------------------------- 0.0/55.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 55.8/55.8 kB 2.8 MB/s eta 0:00:00\n",
      "Collecting pyyaml>=5.3.1\n",
      "  Downloading PyYAML-6.0-cp310-cp310-win_amd64.whl (151 kB)\n",
      "     ---------------------------------------- 0.0/151.7 kB ? eta -:--:--\n",
      "     -------------------------------------- 151.7/151.7 kB 4.4 MB/s eta 0:00:00\n",
      "Collecting importlib-metadata>=4.13.0\n",
      "  Downloading importlib_metadata-6.7.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from click->nltk) (0.4.6)\n",
      "Collecting jupyterlab-widgets~=3.0.7\n",
      "  Downloading jupyterlab_widgets-3.0.7-py3-none-any.whl (198 kB)\n",
      "     ---------------------------------------- 0.0/198.2 kB ? eta -:--:--\n",
      "     -------------------------------------- 198.2/198.2 kB 6.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipywidgets>=7.0.0->swifter) (6.19.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipywidgets>=7.0.0->swifter) (8.7.0)\n",
      "Collecting widgetsnbextension~=4.0.7\n",
      "  Downloading widgetsnbextension-4.0.7-py3-none-any.whl (2.1 MB)\n",
      "     ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "     -------------------------------- ------- 1.7/2.1 MB 35.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.1/2.1 MB 26.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipywidgets>=7.0.0->swifter) (5.8.0)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (6.2)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (24.0.1)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (7.4.8)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (0.1.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (1.5.6)\n",
      "Requirement already satisfied: debugpy>=1.0 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (1.6.4)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.11 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (3.0.36)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (0.7.5)\n",
      "Requirement already satisfied: backcall in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (0.2.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (2.13.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (0.6.2)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (0.18.2)\n",
      "Requirement already satisfied: decorator in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (5.1.1)\n",
      "Collecting locket\n",
      "  Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (5.1.0)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (0.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from prompt-toolkit<3.1.0,>=3.0.11->ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (0.2.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (0.2.2)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (2.2.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (1.2.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (2.6.0)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (305)\n",
      "Installing collected packages: webencodings, zipp, widgetsnbextension, toolz, pyyaml, locket, jupyterlab-widgets, fsspec, cloudpickle, bleach, partd, importlib-metadata, dask, ipywidgets, swifter\n",
      "  Running setup.py install for swifter: started\n",
      "  Running setup.py install for swifter: finished with status 'done'\n",
      "Successfully installed bleach-6.0.0 cloudpickle-2.2.1 dask-2023.6.1 fsspec-2023.6.0 importlib-metadata-6.7.0 ipywidgets-8.0.6 jupyterlab-widgets-3.0.7 locket-1.0.0 partd-1.4.0 pyyaml-6.0 swifter-1.3.5 toolz-0.12.0 webencodings-0.5.1 widgetsnbextension-4.0.7 zipp-3.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: swifter is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: C:\\Users\\carde\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install Unidecode nltk emoji pandas autocorrect swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class DataPreprocessor:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.data = []\n",
    "\n",
    "    def load_data_from_csv(self, filepath):\n",
    "        df = pd.read_csv(filepath)\n",
    "        self.data.append(df)\n",
    "\n",
    "    def combine_data(self):\n",
    "        self.data = pd.concat(self.data)\n",
    "        self.data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from collections import defaultdict\n",
    "\n",
    "import emoji\n",
    "import string\n",
    "from itertools import tee\n",
    "import csv\n",
    "import json\n",
    "import re\n",
    "from multiprocessing import Pool, cpu_count\n",
    "class Indexer:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.inverted_index = defaultdict(dict)\n",
    "        self.emoji_dict = defaultdict()\n",
    "        self.last_emoji_id = 0\n",
    "        self.stopwords = nltk.corpus.stopwords.words('english')\n",
    "        self.stopwords += list(string.punctuation)\n",
    "        self.punctuation = list(string.punctuation)\n",
    "        self.ps = PorterStemmer()\n",
    "        self.tknzr = TweetTokenizer(strip_handles=True, reduce_len=True, preserve_case=True)\n",
    "\n",
    "    def _clean_text(self, text: string):\n",
    "        text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
    "        words = self.tknzr.tokenize(text)\n",
    "        words = [self.ps.stem(a) for a in words if a not in self.punctuation] #if a not in self.stopwords\n",
    "        return words\n",
    "\n",
    "    def _generate_emoji_id(self, term):\n",
    "        self.last_emoji_id += 1\n",
    "        return self.last_emoji_id\n",
    "\n",
    "    def index_data(self, text):\n",
    "        words = self._clean_text(text)\n",
    "        # loop backwards\n",
    "        offset = -1\n",
    "        emoji_anchor = ''\n",
    "         # Save any emoji, count each successive word as offset +1\n",
    "        for i in range(len(words)-1,-1,-1):\n",
    "            word = words[i]\n",
    "            if emoji.purely_emoji(word):\n",
    "                # group consecutive emojis\n",
    "                emoji_anchor = emoji.demojize(word) + emoji_anchor if offset <= 1 else emoji.demojize(word)\n",
    "                offset = 0\n",
    "            else:\n",
    "                self.inverted_index.setdefault(word, {'count': 0, 'emojis': {}})\n",
    "                self.inverted_index[word]['count'] += 1\n",
    "\n",
    "                if len(emoji_anchor) > 0:\n",
    "                    if emoji_anchor not in self.emoji_dict:\n",
    "                        self.emoji_dict[emoji_anchor] = self._generate_emoji_id(emoji_anchor)\n",
    "                    emoji_id = self.emoji_dict[emoji_anchor]\n",
    "                    self.inverted_index[word]['emojis'].setdefault(emoji_id, [])\n",
    "                    self.inverted_index[word]['emojis'][emoji_id].append(offset)\n",
    "            offset+=1\n",
    "\n",
    "    def _findMedian(self, a):\n",
    "        sorted(a)\n",
    "        n = len(a)\n",
    "        if n % 2 != 0:\n",
    "            return float(a[int(n/2)])\n",
    "    \n",
    "        return float((a[int((n-1)/2)] +\n",
    "                    a[int(n/2)])/2.0)\n",
    "\n",
    "    def save_metadata(self, filepath):\n",
    "        flipped_dict = {value: key for key, value in self.emoji_dict.items()}\n",
    "\n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(flipped_dict, f)\n",
    "\n",
    "    def save_index(self, filepath):\n",
    "        new_dict = {}\n",
    "        for k in self.inverted_index:\n",
    "            new_dict[k] = self.inverted_index[k].copy()\n",
    "            for x in self.inverted_index[k]['emojis']:\n",
    "                new_dict[k]['emojis'][x] = self._findMedian(self.inverted_index[k]['emojis'][x])\n",
    "        with open(f'{filepath}.json', 'w') as f:\n",
    "            json.dump(new_dict, f)\n",
    "        \n",
    "        with open(f'{filepath}.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            for word in new_dict:\n",
    "                writer.writerow([word, new_dict[word]['count'], new_dict[word]['emojis']])\n",
    "\n",
    "\n",
    "    def read_index(self, filepath):\n",
    "        self.inverted_index = defaultdict(dict)\n",
    "        with open(filepath, 'r') as f:\n",
    "            self.inverted_index = json.load(f)\n",
    "    \n",
    "    def read_meta(self, filepath):\n",
    "        self.emoji_dict = defaultdict()\n",
    "        with open(filepath, 'r') as f:\n",
    "            self.emoji_dict = json.load(f)\n",
    "\n",
    "    def process_data(self, data):\n",
    "        with Pool(cpu_count()) as p:\n",
    "            p.map(self.index_data, data)\n",
    "\n",
    "# i = Indexer()\n",
    "# i.index_data(\"good Good   luckğŸ˜®â€ğŸ’¨, good you dawg qhoo . aah ğŸ‘ğŸ¼ğŸ˜®â€ğŸ’¨\")\n",
    "# i.save_index(\"output/index\")\n",
    "# i.save_metadata(\"output/meta.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class QueryEngine:\n",
    "\n",
    "    def __init__(self, index, meta):\n",
    "        self.index = index\n",
    "        self.meta = meta\n",
    "        self.query_result = defaultdict(dict)\n",
    "\n",
    "    # Vanilla (ish) tf-idf\n",
    "    def process_query_tf_idf(self, search_query, cleaner, n_per_word=3, n_overall=5):\n",
    "        self.query_result = defaultdict(dict)\n",
    "        query = cleaner(search_query)\n",
    "        query_length = len(query)\n",
    "        n = len(self.index)\n",
    "        for i, query_term in enumerate(query):\n",
    "            postings = self.index[query_term] if query_term in self.index else None\n",
    "            if postings is None:\n",
    "                continue\n",
    "            query_weight = 1.0\n",
    "            query_tf = len([q for q in query if q == query_term])\n",
    "            query_weight *= query_tf\n",
    "\n",
    "            df_t = len(postings)\n",
    "            idf_t = math.log(n / df_t)\n",
    "            for emo, median in postings['emojis'].items():\n",
    "                if emo not in self.query_result:\n",
    "                    self.query_result[emo] = {'query': query_term, 'raw': emo,'score': 0}\n",
    "                self.query_result[emo]['score'] += ((query_tf * idf_t) / median) / query_length\n",
    "\n",
    "        all_emojis = [(emoji, info) for emoji, info in self.query_result.items()]\n",
    "        all_emojis.sort(key=lambda x: x[1]['score'], reverse=True)\n",
    "        top_emojis = all_emojis[:n_overall]\n",
    "        #print(f\"The top {n_overall} emojis overall are:\")\n",
    "        return\", \".join(f\"{emoji.emojize(self.meta[emo[0]])}\" for emo in top_emojis) #  {emo[1]['score']:.2f}\n",
    "\n",
    "\n",
    "    def _positional_intersect(self, accumulator, newresults, k):\n",
    "        if accumulator is [] or newresults is None:\n",
    "            return accumulator\n",
    "        \n",
    "        answer = list()\n",
    "        for x_em, x_offsets in accumulator['emojis'].items():\n",
    "            for y_em, y_offsets in newresults['emojis'].items():\n",
    "                if(x_em == y_em):\n",
    "                    answer.append(x_em)\n",
    "        return answer\n",
    "    \n",
    "    def phrase_query(self, search_query, cleaner):\n",
    "        query = cleaner(search_query)\n",
    "        print(query)\n",
    "        results = self.index[query[0]] if query[0] in self.index else None\n",
    "        for term in query[:1]:\n",
    "            matches = self.index[term] if term in self.index else None\n",
    "            results = self._positional_intersect(results, matches, 3)\n",
    "        print(results[:5])\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import glob\n",
    "import swifter\n",
    "preprocessor = DataPreprocessor()\n",
    "\n",
    "csv_files = glob.glob('data/clean/*.csv')\n",
    "\n",
    "for filename in csv_files:\n",
    "    preprocessor.load_data_from_csv(filename)\n",
    "preprocessor.combine_data()\n",
    "preprocessor.data.reset_index(drop=True)\n",
    "# Index data\n",
    "indexer = Indexer()\n",
    "\n",
    "preprocessor.data['text'].swifter.apply(lambda x: indexer.index_data(x))\n",
    "print(\"preprocessor done, writing to disk\")\n",
    "\n",
    "indexer.save_index('output/index')\n",
    "indexer.save_metadata('output/meta.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data from file\n"
     ]
    }
   ],
   "source": [
    "print(\"reading data from file\")\n",
    "indexer = Indexer()\n",
    "indexer.read_index(\"output/index.json\")\n",
    "indexer.read_meta(\"output/meta.json\")\n",
    "\n",
    "engine = QueryEngine(indexer.inverted_index, indexer.emoji_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ğŸ, 7.88, are, ğŸ’ªğŸ»ğŸ’ªğŸ», 7.11, are, ğŸ°, 6.67, are, ğŸ”¥ğŸ”¥ğŸ”¥, 6.62, are, ğŸ˜ğŸ’¦, 6.34, you'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query data\n",
    "engine = QueryEngine(indexer.inverted_index, indexer.emoji_dict)\n",
    "query = \"Are you ready to take your resume to the next level?\"\n",
    "#engine.phrase_query(query, indexer._clean_text)\n",
    "engine.process_query_tf_idf(query, indexer._clean_text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm feeling happy. ğŸª, ğŸŒ‘, ğŸ™‹â€â™‚ï¸, ğŸ¥², ğŸ“–\n",
      "I'm feeling very sad. ğŸ™, ğŸ˜¢ğŸ’”, ğŸ˜¯, ğŸƒ, ğŸ˜‚ğŸ˜‚ğŸ˜‚\n",
      "I'm angry with you. ğŸ™ŒğŸ¼, ğŸ‘©, ğŸ˜­, ğŸ˜³ğŸ˜‚, ğŸ…°ï¸\n",
      "I love pizza. âœ”ï¸, ğŸ’˜, ğŸ‘€ğŸ‘€, ğŸ˜“, ğŸ•ğŸ˜ğŸ‘Œ\n",
      "I dislike broccoli. ğŸ˜, ğŸ™„, ğŸŒš, ğŸ˜›, ğŸ‘ğŸ»\n",
      "The sunrise this morning was beautiful. â˜€ï¸, ğŸ™ŒğŸ¼ğŸ™ğŸ¼, ğŸ‘ğŸ¾ğŸ™ŒğŸ¾, ğŸ™ğŸ», ğŸ¤Œ\n",
      "It's been a long, tiring day. ğŸŒ›, ğŸ…±ï¸, ğŸ˜¨, â˜”, ğŸ‘\n",
      "I just won the lottery! ğŸ™, ğŸ˜­, ğŸ¶, â­â­, ğŸ¥€ğŸ”¥\n",
      "I can't believe we lost the game. ğŸ‘, ğŸš«, ğŸ¤·, ğŸ˜‚ğŸ˜­, ğŸ“±\n",
      "I'm so excited for the weekend. ğŸ”¥ğŸ”¥, ğŸ‘, ğŸ”ª, ğŸ¤ğŸ½, ğŸ‘\n",
      "The movie was boring. ğŸ®, ğŸ˜®, ğŸ™ƒ, ğŸ¤™ğŸ», ğŸ’€\n",
      "That was the best concert ever! ğŸ˜š, ğŸ’‹, ğŸ˜›, ğŸ¤—, ğŸ•\n",
      "I'm scared of spiders. ğŸ‘€, ğŸ˜², ğŸ˜­ğŸ˜‚, ğŸ’”, ğŸ‘\n",
      "My heart is broken. ğŸ‘ğŸ», ğŸ˜­ğŸ˜­, ğŸ”‘, ğŸ˜ğŸ˜ğŸ˜ğŸ˜, ğŸ‘‹ğŸ¼\n",
      "I can't wait for my birthday. ğŸ’ğŸ™Œ, ğŸ˜‚ğŸ˜‚, ğŸ™ˆğŸ™ˆ, ğŸ­, ğŸ˜“\n",
      "I am feeling so peaceful right now. âœ¨, ğŸ˜ğŸ˜ğŸ˜, ğŸ˜ª, ğŸ¥°, â˜ºï¸\n",
      "That joke was hilarious. ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚, ğŸ¥, ğŸ¸, ğŸ˜‚ğŸ˜‚ğŸ‘, ğŸ˜‚â¤ï¸\n",
      "I'm feeling pretty indifferent about the whole situation. ğŸ˜, ğŸ—£ï¸, ğŸ™„, ğŸ¤’, ğŸŒ\n",
      "I just got a promotion! ğŸ™ğŸ¼ğŸ”¥, ğŸ…±ï¸, ğŸš“, ğŸ™‡, 2ï¸âƒ£\n",
      "I feel like crying. ğŸ¥², ğŸ¤”, ğŸ˜ğŸ˜, ğŸ”ª, ğŸ˜ŠğŸ‘ğŸ¼\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"I'm feeling happy.\",\n",
    "    \"I'm feeling very sad.\",\n",
    "    \"I'm angry with you.\",\n",
    "    \"I love pizza.\",\n",
    "    \"I dislike broccoli.\",\n",
    "    \"The sunrise this morning was beautiful.\",\n",
    "    \"It's been a long, tiring day.\",\n",
    "    \"I just won the lottery!\",\n",
    "    \"I can't believe we lost the game.\",\n",
    "    \"I'm so excited for the weekend.\",\n",
    "    \"The movie was boring.\",\n",
    "    \"That was the best concert ever!\",\n",
    "    \"I'm scared of spiders.\",\n",
    "    \"My heart is broken.\",\n",
    "    \"I can't wait for my birthday.\",\n",
    "    \"I am feeling so peaceful right now.\",\n",
    "    \"That joke was hilarious.\",\n",
    "    \"I'm feeling pretty indifferent about the whole situation.\",\n",
    "    \"I just got a promotion!\",\n",
    "    \"I feel like crying.\",\n",
    "    \"I can't stand the heat.\",\n",
    "    \"I am freezing!\",\n",
    "    \"That was a delicious meal.\",\n",
    "    \"I am on top of the world!\",\n",
    "    \"I just had a terrible day at work.\",\n",
    "    \"I'm worried about my exam.\",\n",
    "    \"That book was thrilling!\",\n",
    "    \"I'm feeling adventurous.\",\n",
    "    \"I'm feeling so lazy today.\",\n",
    "    \"That was a scary movie.\",\n",
    "    \"I am grateful for my friends.\",\n",
    "    \"The party was a blast!\",\n",
    "    \"That test was really hard.\",\n",
    "    \"I feel loved.\",\n",
    "    \"I feel so rejected.\",\n",
    "    \"I'm bursting with joy.\",\n",
    "    \"I'm disgusted by the trash.\",\n",
    "    \"That was a stressful situation.\",\n",
    "    \"I'm so proud of my team.\",\n",
    "    \"I'm amazed by the view.\",\n",
    "    \"That song was touching.\",\n",
    "    \"I feel so lonely.\",\n",
    "    \"I'm feeling nostalgic.\",\n",
    "    \"The race was intense.\",\n",
    "    \"That was an awkward conversation.\",\n",
    "    \"I feel inspired.\",\n",
    "    \"I'm feeling playful.\",\n",
    "    \"I'm feeling ambitious.\",\n",
    "    \"I'm feeling doubtful.\",\n",
    "    \"That was a surprising result.\",\n",
    "    \"I'm feeling content.\",\n",
    "    \"I'm so disappointed.\",\n",
    "    \"I'm feeling hopeful.\",\n",
    "    \"That was a frustrating experience.\",\n",
    "    \"I feel so appreciated.\",\n",
    "    \"I'm confused.\",\n",
    "    \"I'm feeling motivated.\",\n",
    "    \"I'm feeling pessimistic.\",\n",
    "    \"I'm feeling apathetic.\",\n",
    "    \"That was an impressive performance.\",\n",
    "    \"I'm curious about the result.\",\n",
    "    \"I'm feeling so relaxed.\",\n",
    "    \"I'm feeling agitated.\",\n",
    "    \"That was a depressing story.\",\n",
    "    \"I'm feeling optimistic.\",\n",
    "    \"I feel so empowered.\",\n",
    "    \"I'm feeling ashamed.\",\n",
    "    \"I'm feeling energized.\",\n",
    "    \"I'm feeling apprehensive.\",\n",
    "    \"I'm feeling delighted.\",\n",
    "    \"I'm feeling guilty.\",\n",
    "    \"That was a challenging puzzle.\",\n",
    "    \"I'm feeling so refreshed.\",\n",
    "    \"I'm feeling overwhelmed.\",\n",
    "    \"I'm feeling serene.\",\n",
    "    \"I'm feeling vulnerable.\",\n",
    "    \"That was a fascinating lecture.\",\n",
    "    \"I'm feeling proud.\",\n",
    "    \"I'm feeling humiliated.\",\n",
    "    \"I'm feeling so exhilarated.\",\n",
    "    \"I'm feeling regretful.\",\n",
    "    \"I'm feeling contented.\",\n",
    "    \"I'm feeling restless.\",\n",
    "    \"That was an enchanting evening.\",\n",
    "    \"I'm feeling tranquil.\",\n",
    "    \"I'm feeling tormented.\",\n",
    "    \"I'm feeling triumphant.\",\n",
    "    \"I'm feeling desolate.\",\n",
    "    \"I'm feeling blissful.\",\n",
    "    \"I'm feeling distressed.\",\n",
    "    \"I'm feeling jubilant.\",\n",
    "    \"I'm feeling woeful.\",\n",
    "    \"I'm feeling exuberant.\",\n",
    "    \"I'm feeling despondent.\",\n",
    "    \"I'm feeling ecstatic.\",\n",
    "    \"I'm feeling inconsolable.\",\n",
    "    \"I'm feeling rapturous.\",\n",
    "    \"I'm feeling forlorn.\",\n",
    "    \"I'm feeling exhilarated.\",\n",
    "    \"I'm feeling downhearted.\"\n",
    "]\n",
    "\n",
    "for sentence in sentences[:20]:\n",
    "    emojis = engine.process_query_tf_idf(sentence, indexer._clean_text)\n",
    "    print(f\"{sentence} {emojis}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just had the best coffee at @CafeLuv #CoffeeLover ğŸ€, ğŸ¾, ğŸŒš, ğŸ‘ŒğŸ», ğŸ˜©ğŸ‘Œ\n",
      "Getting ready for a Friday night out with the girls! ğŸ’ƒ #FridayFeeling ğŸ™ŒğŸ™Œ, ğŸ¤‘, ğŸ­, ğŸ™ŒğŸ»ğŸ™ŒğŸ»ğŸ™ŒğŸ», ğŸ¤\n",
      "Who else is excited for the new Avengers movie? ğŸ¿ #MarvelFan ğŸ¤™ğŸ¼, ğŸ”‘, ğŸ–•ğŸ½, ğŸ¤”, â—\n",
      "Can't believe how beautiful the sunset was today. ğŸŒ… #NaturePhotography ğŸ¦, â˜€ï¸, ğŸ¤™ğŸ», ğŸ‰, ğŸ˜\n",
      "Dinner at my favorite sushi place ğŸ£ #Foodie ğŸ‘…, ğŸ¤™ğŸ», ğŸ‘€, ğŸ™„, ğŸšŒ\n",
      "Throwback to my trip to Paris last summer ğŸ—¼ #TravelDiaries ğŸ, ğŸ’˜, â‰ï¸, â˜ºï¸, ğŸ˜ğŸ’¦\n",
      "Feeling so blessed to have such amazing people in my life ğŸ¥° #Blessed âœ¨, ğŸ™, ğŸ©, ğŸ™ğŸ¼, ğŸ™ğŸ»ğŸ™ğŸ»ğŸ™ğŸ»\n",
      "Workout done for the day! ğŸ’ª #FitnessGoals ğŸ˜ğŸ™Œ, ğŸ‘, â˜ï¸, ğŸ‘ğŸ½, ğŸ™ğŸ¾ğŸ™ğŸ¾ğŸ™ğŸ¾\n",
      "I could spend all day reading at this quiet little bookstore ğŸ“š #BookWorm ğŸ‘ğŸ¼, ğŸ‘‡ğŸ», ğŸ¥, ğŸ‘‡ğŸ‘‡, ğŸ’•\n",
      "Had an awesome time at the concert last night! ğŸ¤ #LiveMusic ğŸ˜”, ğŸƒ, ğŸŒš, ğŸ’Š, ğŸ˜ˆ\n",
      "I can assist you with booking a flight âœˆï¸ #ChatBot ğŸ‘‰, ğŸ™ğŸ¼, ğŸ˜â¤ï¸, ğŸ˜», ğŸ’š\n",
      "What can I help you find today? ğŸ” #CustomerService ğŸ˜”âœŒï¸, ğŸ‘”, âœ”ï¸, ğŸ™ğŸ¼âœ¨, ğŸ˜\n",
      "Processing your request now... â³ #AI ğŸ˜«, ğŸ™ğŸ½, ğŸ‘‡ğŸ‘‡, ğŸ†, ğŸ˜”\n",
      "Your order has been placed! ğŸ›ï¸ #ShoppingBot ğŸŒ³, ğŸ¤”, ğŸ™ŒğŸ½ğŸ™ŒğŸ½, ğŸ’Œ, ğŸ’«\n",
      "The weather in New York today is sunny with a high of 75 degrees ğŸŒ #WeatherBot ğŸ˜, âœŒï¸, ğŸ˜, ğŸ§, ğŸ˜‘\n",
      "Directing you to a customer service representative now ğŸ“ #HelpBot ğŸ˜ƒ, ğŸ™ŒğŸ¼, ğŸ™ğŸ™, ğŸ’œ, ğŸ‘‡\n",
      "That information is not currently available. Can I assist with anything else? â“ #InfoBot ğŸ‘ğŸ», ğŸ‘, ğŸ‘ğŸ», ğŸ”¥, ğŸƒ\n",
      "You have 3 new notifications ğŸ“¬ #ReminderBot ğŸ˜­âœ‹ğŸ», ğŸ’•, ğŸŒ», ğŸ‘‘, ğŸŒªï¸\n",
      "You successfully completed your daily step goal! ğŸƒâ€â™€ï¸ #HealthBot ğŸ™ŒğŸ¼, ğŸ‘‘, ğŸ˜ƒ, ğŸ‘…, ğŸ‘Œ\n",
      "Your package has been shipped and is on its way ğŸ“¦ #DeliveryUpdate ğŸ‘œ, âœˆï¸, ğŸ“¦, ğŸ”Š, ğŸ‘\n"
     ]
    }
   ],
   "source": [
    "social_media_sentences = [\n",
    "    \"Just had the best coffee at @CafeLuv â˜•ï¸ #CoffeeLover\",\n",
    "    \"Getting ready for a Friday night out with the girls! ğŸ’ƒ #FridayFeeling\",\n",
    "    \"Who else is excited for the new Avengers movie? ğŸ¿ #MarvelFan\",\n",
    "    \"Can't believe how beautiful the sunset was today. ğŸŒ… #NaturePhotography\",\n",
    "    \"Dinner at my favorite sushi place ğŸ£ #Foodie\",\n",
    "    \"Throwback to my trip to Paris last summer ğŸ—¼ #TravelDiaries\",\n",
    "    \"Feeling so blessed to have such amazing people in my life ğŸ¥° #Blessed\",\n",
    "    \"Workout done for the day! ğŸ’ª #FitnessGoals\",\n",
    "    \"I could spend all day reading at this quiet little bookstore ğŸ“š #BookWorm\",\n",
    "    \"Had an awesome time at the concert last night! ğŸ¤ #LiveMusic\",\n",
    "    \"I can assist you with booking a flight âœˆï¸ #ChatBot\",\n",
    "    \"What can I help you find today? ğŸ” #CustomerService\",\n",
    "    \"Processing your request now... â³ #AI\",\n",
    "    \"Your order has been placed! ğŸ›ï¸ #ShoppingBot\",\n",
    "    \"The weather in New York today is sunny with a high of 75 degrees ğŸŒ #WeatherBot\",\n",
    "    \"Directing you to a customer service representative now ğŸ“ #HelpBot\",\n",
    "    \"That information is not currently available. Can I assist with anything else? â“ #InfoBot\",\n",
    "    \"You have 3 new notifications ğŸ“¬ #ReminderBot\",\n",
    "    \"You successfully completed your daily step goal! ğŸƒâ€â™€ï¸ #HealthBot\",\n",
    "    \"Your package has been shipped and is on its way ğŸ“¦ #DeliveryUpdate\"\n",
    "]\n",
    "\n",
    "for sentence in social_media_sentences:\n",
    "    emojis = engine.process_query_tf_idf(sentence, indexer._clean_text)\n",
    "    print(f\"{sentence} {emojis}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
