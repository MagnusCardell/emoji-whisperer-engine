{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Unidecode in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.3.6)\n",
      "Requirement already satisfied: nltk in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (3.8.1)\n",
      "Requirement already satisfied: emoji in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.6.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.0.2)\n",
      "Requirement already satisfied: autocorrect in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.6.1)\n",
      "Collecting swifter\n",
      "  Downloading swifter-1.3.5.tar.gz (490 kB)\n",
      "     ---------------------------------------- 0.0/490.6 kB ? eta -:--:--\n",
      "     ------- ------------------------------ 102.4/490.6 kB 3.0 MB/s eta 0:00:01\n",
      "     -------------------------------- ----- 419.8/490.6 kB 5.3 MB/s eta 0:00:01\n",
      "     --------------------------------- ---- 430.1/490.6 kB 3.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- 490.6/490.6 kB 3.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: click in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (1.24.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: psutil>=5.6.6 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from swifter) (5.9.4)\n",
      "Collecting dask[dataframe]>=2.10.0\n",
      "  Downloading dask-2023.6.1-py3-none-any.whl (1.2 MB)\n",
      "     ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "     ---------------------------------------  1.2/1.2 MB 24.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.2/1.2 MB 18.7 MB/s eta 0:00:00\n",
      "Collecting ipywidgets>=7.0.0\n",
      "  Downloading ipywidgets-8.0.6-py3-none-any.whl (138 kB)\n",
      "     ---------------------------------------- 0.0/138.3 kB ? eta -:--:--\n",
      "     -------------------------------------- 138.3/138.3 kB 8.0 MB/s eta 0:00:00\n",
      "Collecting cloudpickle>=0.2.2\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: parso>0.4.0 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from swifter) (0.8.3)\n",
      "Collecting bleach>=3.1.1\n",
      "  Downloading bleach-6.0.0-py3-none-any.whl (162 kB)\n",
      "     ---------------------------------------- 0.0/162.5 kB ? eta -:--:--\n",
      "     ------------------------------------- 162.5/162.5 kB 10.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from bleach>=3.1.1->swifter) (1.16.0)\n",
      "Collecting webencodings\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Collecting partd>=1.2.0\n",
      "  Downloading partd-1.4.0-py3-none-any.whl (18 kB)\n",
      "Collecting fsspec>=2021.09.0\n",
      "  Downloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "     ---------------------------------------- 0.0/163.8 kB ? eta -:--:--\n",
      "     ------------------------------------- 163.8/163.8 kB 10.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from dask[dataframe]>=2.10.0->swifter) (22.0)\n",
      "Collecting toolz>=0.10.0\n",
      "  Downloading toolz-0.12.0-py3-none-any.whl (55 kB)\n",
      "     ---------------------------------------- 0.0/55.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 55.8/55.8 kB 2.8 MB/s eta 0:00:00\n",
      "Collecting pyyaml>=5.3.1\n",
      "  Downloading PyYAML-6.0-cp310-cp310-win_amd64.whl (151 kB)\n",
      "     ---------------------------------------- 0.0/151.7 kB ? eta -:--:--\n",
      "     -------------------------------------- 151.7/151.7 kB 4.4 MB/s eta 0:00:00\n",
      "Collecting importlib-metadata>=4.13.0\n",
      "  Downloading importlib_metadata-6.7.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from click->nltk) (0.4.6)\n",
      "Collecting jupyterlab-widgets~=3.0.7\n",
      "  Downloading jupyterlab_widgets-3.0.7-py3-none-any.whl (198 kB)\n",
      "     ---------------------------------------- 0.0/198.2 kB ? eta -:--:--\n",
      "     -------------------------------------- 198.2/198.2 kB 6.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipywidgets>=7.0.0->swifter) (6.19.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipywidgets>=7.0.0->swifter) (8.7.0)\n",
      "Collecting widgetsnbextension~=4.0.7\n",
      "  Downloading widgetsnbextension-4.0.7-py3-none-any.whl (2.1 MB)\n",
      "     ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "     -------------------------------- ------- 1.7/2.1 MB 35.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.1/2.1 MB 26.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipywidgets>=7.0.0->swifter) (5.8.0)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (6.2)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (24.0.1)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (7.4.8)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (0.1.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (1.5.6)\n",
      "Requirement already satisfied: debugpy>=1.0 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (1.6.4)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.11 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (3.0.36)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (0.7.5)\n",
      "Requirement already satisfied: backcall in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (0.2.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (2.13.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (0.6.2)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (0.18.2)\n",
      "Requirement already satisfied: decorator in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (5.1.1)\n",
      "Collecting locket\n",
      "  Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (5.1.0)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (0.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from prompt-toolkit<3.1.0,>=3.0.11->ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (0.2.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (0.2.2)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (2.2.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (1.2.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (2.6.0)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (305)\n",
      "Installing collected packages: webencodings, zipp, widgetsnbextension, toolz, pyyaml, locket, jupyterlab-widgets, fsspec, cloudpickle, bleach, partd, importlib-metadata, dask, ipywidgets, swifter\n",
      "  Running setup.py install for swifter: started\n",
      "  Running setup.py install for swifter: finished with status 'done'\n",
      "Successfully installed bleach-6.0.0 cloudpickle-2.2.1 dask-2023.6.1 fsspec-2023.6.0 importlib-metadata-6.7.0 ipywidgets-8.0.6 jupyterlab-widgets-3.0.7 locket-1.0.0 partd-1.4.0 pyyaml-6.0 swifter-1.3.5 toolz-0.12.0 webencodings-0.5.1 widgetsnbextension-4.0.7 zipp-3.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: swifter is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: C:\\Users\\carde\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install Unidecode nltk emoji pandas autocorrect swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class DataPreprocessor:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.data = []\n",
    "\n",
    "    def load_data_from_csv(self, filepath):\n",
    "        df = pd.read_csv(filepath)\n",
    "        self.data.append(df)\n",
    "\n",
    "    def combine_data(self):\n",
    "        self.data = pd.concat(self.data)\n",
    "        self.data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from collections import defaultdict\n",
    "\n",
    "import emoji\n",
    "import string\n",
    "from itertools import tee\n",
    "import csv\n",
    "import json\n",
    "import re\n",
    "from multiprocessing import Pool, cpu_count\n",
    "class Indexer:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.inverted_index = defaultdict(dict)\n",
    "        self.emoji_dict = defaultdict()\n",
    "        self.last_emoji_id = 0\n",
    "        self.stopwords = nltk.corpus.stopwords.words('english')\n",
    "        self.stopwords += list(string.punctuation)\n",
    "        self.punctuation = list(string.punctuation)\n",
    "        self.ps = PorterStemmer()\n",
    "        self.tknzr = TweetTokenizer(strip_handles=True, reduce_len=True, preserve_case=True)\n",
    "\n",
    "    def _clean_text(self, text: string):\n",
    "        text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
    "        words = self.tknzr.tokenize(text)\n",
    "        words = [self.ps.stem(a) for a in words if a not in self.punctuation] #if a not in self.stopwords\n",
    "        return words\n",
    "\n",
    "    def _generate_emoji_id(self, term):\n",
    "        self.last_emoji_id += 1\n",
    "        return self.last_emoji_id\n",
    "\n",
    "    def index_data(self, text):\n",
    "        words = self._clean_text(text)\n",
    "        # loop backwards\n",
    "        offset = -1\n",
    "        emoji_anchor = ''\n",
    "         # Save any emoji, count each successive word as offset +1\n",
    "        for i in range(len(words)-1,-1,-1):\n",
    "            word = words[i]\n",
    "            if emoji.purely_emoji(word):\n",
    "                # group consecutive emojis\n",
    "                emoji_anchor = emoji.demojize(word) + emoji_anchor if offset <= 1 else emoji.demojize(word)\n",
    "                offset = 0\n",
    "            else:\n",
    "                self.inverted_index.setdefault(word, {'count': 0, 'emojis': {}})\n",
    "                self.inverted_index[word]['count'] += 1\n",
    "\n",
    "                if len(emoji_anchor) > 0:\n",
    "                    if emoji_anchor not in self.emoji_dict:\n",
    "                        self.emoji_dict[emoji_anchor] = self._generate_emoji_id(emoji_anchor)\n",
    "                    emoji_id = self.emoji_dict[emoji_anchor]\n",
    "                    self.inverted_index[word]['emojis'].setdefault(emoji_id, [])\n",
    "                    self.inverted_index[word]['emojis'][emoji_id].append(offset)\n",
    "            offset+=1\n",
    "\n",
    "    def _findMedian(self, a):\n",
    "        sorted(a)\n",
    "        n = len(a)\n",
    "        if n % 2 != 0:\n",
    "            return float(a[int(n/2)])\n",
    "    \n",
    "        return float((a[int((n-1)/2)] +\n",
    "                    a[int(n/2)])/2.0)\n",
    "\n",
    "    def save_metadata(self, filepath):\n",
    "        flipped_dict = {value: key for key, value in self.emoji_dict.items()}\n",
    "\n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(flipped_dict, f)\n",
    "\n",
    "    def save_index(self, filepath):\n",
    "        new_dict = {}\n",
    "        for k in self.inverted_index:\n",
    "            new_dict[k] = self.inverted_index[k].copy()\n",
    "            for x in self.inverted_index[k]['emojis']:\n",
    "                new_dict[k]['emojis'][x] = self._findMedian(self.inverted_index[k]['emojis'][x])\n",
    "        with open(f'{filepath}.json', 'w') as f:\n",
    "            json.dump(new_dict, f)\n",
    "        \n",
    "        with open(f'{filepath}.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            for word in new_dict:\n",
    "                writer.writerow([word, new_dict[word]['count'], new_dict[word]['emojis']])\n",
    "\n",
    "\n",
    "    def read_index(self, filepath):\n",
    "        self.inverted_index = defaultdict(dict)\n",
    "        with open(filepath, 'r') as f:\n",
    "            self.inverted_index = json.load(f)\n",
    "    \n",
    "    def read_meta(self, filepath):\n",
    "        self.emoji_dict = defaultdict()\n",
    "        with open(filepath, 'r') as f:\n",
    "            self.emoji_dict = json.load(f)\n",
    "\n",
    "    def process_data(self, data):\n",
    "        with Pool(cpu_count()) as p:\n",
    "            p.map(self.index_data, data)\n",
    "\n",
    "# i = Indexer()\n",
    "# i.index_data(\"good Good   luck😮‍💨, good you dawg qhoo . aah 👏🏼😮‍💨\")\n",
    "# i.save_index(\"output/index\")\n",
    "# i.save_metadata(\"output/meta.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class QueryEngine:\n",
    "\n",
    "    def __init__(self, index, meta):\n",
    "        self.index = index\n",
    "        self.meta = meta\n",
    "        self.query_result = defaultdict(dict)\n",
    "\n",
    "    # Vanilla (ish) tf-idf\n",
    "    def process_query_tf_idf(self, search_query, cleaner, n_per_word=3, n_overall=5):\n",
    "        self.query_result = defaultdict(dict)\n",
    "        query = cleaner(search_query)\n",
    "        query_length = len(query)\n",
    "        n = len(self.index)\n",
    "        for i, query_term in enumerate(query):\n",
    "            postings = self.index[query_term] if query_term in self.index else None\n",
    "            if postings is None:\n",
    "                continue\n",
    "            query_weight = 1.0\n",
    "            query_tf = len([q for q in query if q == query_term])\n",
    "            query_weight *= query_tf\n",
    "\n",
    "            df_t = len(postings)\n",
    "            idf_t = math.log(n / df_t)\n",
    "            for emo, median in postings['emojis'].items():\n",
    "                if emo not in self.query_result:\n",
    "                    self.query_result[emo] = {'query': query_term, 'raw': emo,'score': 0}\n",
    "                self.query_result[emo]['score'] += ((query_tf * idf_t) / median) / query_length\n",
    "\n",
    "        all_emojis = [(emoji, info) for emoji, info in self.query_result.items()]\n",
    "        all_emojis.sort(key=lambda x: x[1]['score'], reverse=True)\n",
    "        top_emojis = all_emojis[:n_overall]\n",
    "        #print(f\"The top {n_overall} emojis overall are:\")\n",
    "        return\", \".join(f\"{emoji.emojize(self.meta[emo[0]])}\" for emo in top_emojis) #  {emo[1]['score']:.2f}\n",
    "\n",
    "\n",
    "    def _positional_intersect(self, accumulator, newresults, k):\n",
    "        if accumulator is [] or newresults is None:\n",
    "            return accumulator\n",
    "        \n",
    "        answer = list()\n",
    "        for x_em, x_offsets in accumulator['emojis'].items():\n",
    "            for y_em, y_offsets in newresults['emojis'].items():\n",
    "                if(x_em == y_em):\n",
    "                    answer.append(x_em)\n",
    "        return answer\n",
    "    \n",
    "    def phrase_query(self, search_query, cleaner):\n",
    "        query = cleaner(search_query)\n",
    "        print(query)\n",
    "        results = self.index[query[0]] if query[0] in self.index else None\n",
    "        for term in query[:1]:\n",
    "            matches = self.index[term] if term in self.index else None\n",
    "            results = self._positional_intersect(results, matches, 3)\n",
    "        print(results[:5])\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import glob\n",
    "import swifter\n",
    "preprocessor = DataPreprocessor()\n",
    "\n",
    "csv_files = glob.glob('data/clean/*.csv')\n",
    "\n",
    "for filename in csv_files:\n",
    "    preprocessor.load_data_from_csv(filename)\n",
    "preprocessor.combine_data()\n",
    "preprocessor.data.reset_index(drop=True)\n",
    "# Index data\n",
    "indexer = Indexer()\n",
    "\n",
    "preprocessor.data['text'].swifter.apply(lambda x: indexer.index_data(x))\n",
    "print(\"preprocessor done, writing to disk\")\n",
    "\n",
    "indexer.save_index('output/index')\n",
    "indexer.save_metadata('output/meta.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data from file\n"
     ]
    }
   ],
   "source": [
    "print(\"reading data from file\")\n",
    "indexer = Indexer()\n",
    "indexer.read_index(\"output/index.json\")\n",
    "indexer.read_meta(\"output/meta.json\")\n",
    "\n",
    "engine = QueryEngine(indexer.inverted_index, indexer.emoji_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'🍞, 7.88, are, 💪🏻💪🏻, 7.11, are, 🍰, 6.67, are, 🔥🔥🔥, 6.62, are, 😎💦, 6.34, you'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query data\n",
    "engine = QueryEngine(indexer.inverted_index, indexer.emoji_dict)\n",
    "query = \"Are you ready to take your resume to the next level?\"\n",
    "#engine.phrase_query(query, indexer._clean_text)\n",
    "engine.process_query_tf_idf(query, indexer._clean_text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm feeling happy. 🐪, 🌑, 🙋‍♂️, 🥲, 📖\n",
      "I'm feeling very sad. 🙁, 😢💔, 😯, 🍃, 😂😂😂\n",
      "I'm angry with you. 🙌🏼, 👩, 😭, 😳😂, 🅰️\n",
      "I love pizza. ✔️, 💘, 👀👀, 😓, 🍕😍👌\n",
      "I dislike broccoli. 😍, 🙄, 🌚, 😛, 👎🏻\n",
      "The sunrise this morning was beautiful. ☀️, 🙌🏼🙏🏼, 👏🏾🙌🏾, 🙏🏻, 🤌\n",
      "It's been a long, tiring day. 🌛, 🅱️, 😨, ☔, 👏\n",
      "I just won the lottery! 🙁, 😭, 🎶, ⭐⭐, 🥀🔥\n",
      "I can't believe we lost the game. 👏, 🚫, 🤷, 😂😭, 📱\n",
      "I'm so excited for the weekend. 🔥🔥, 👍, 🔪, 🤞🏽, 🍑\n",
      "The movie was boring. 🎮, 😮, 🙃, 🤙🏻, 💀\n",
      "That was the best concert ever! 😚, 💋, 😛, 🤗, 🐕\n",
      "I'm scared of spiders. 👀, 😲, 😭😂, 💔, 👐\n",
      "My heart is broken. 👏🏻, 😭😭, 🔑, 😍😍😍😍, 👋🏼\n",
      "I can't wait for my birthday. 💎🙌, 😂😂, 🙈🙈, 🍭, 😓\n",
      "I am feeling so peaceful right now. ✨, 😍😍😍, 😪, 🥰, ☺️\n",
      "That joke was hilarious. 😂😂😂😂😂, 🎥, 🐸, 😂😂👍, 😂❤️\n",
      "I'm feeling pretty indifferent about the whole situation. 😎, 🗣️, 🙄, 🤒, 🌞\n",
      "I just got a promotion! 🙏🏼🔥, 🅱️, 🚓, 🙇, 2️⃣\n",
      "I feel like crying. 🥲, 🤔, 😍😍, 🔪, 😊👍🏼\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"I'm feeling happy.\",\n",
    "    \"I'm feeling very sad.\",\n",
    "    \"I'm angry with you.\",\n",
    "    \"I love pizza.\",\n",
    "    \"I dislike broccoli.\",\n",
    "    \"The sunrise this morning was beautiful.\",\n",
    "    \"It's been a long, tiring day.\",\n",
    "    \"I just won the lottery!\",\n",
    "    \"I can't believe we lost the game.\",\n",
    "    \"I'm so excited for the weekend.\",\n",
    "    \"The movie was boring.\",\n",
    "    \"That was the best concert ever!\",\n",
    "    \"I'm scared of spiders.\",\n",
    "    \"My heart is broken.\",\n",
    "    \"I can't wait for my birthday.\",\n",
    "    \"I am feeling so peaceful right now.\",\n",
    "    \"That joke was hilarious.\",\n",
    "    \"I'm feeling pretty indifferent about the whole situation.\",\n",
    "    \"I just got a promotion!\",\n",
    "    \"I feel like crying.\",\n",
    "    \"I can't stand the heat.\",\n",
    "    \"I am freezing!\",\n",
    "    \"That was a delicious meal.\",\n",
    "    \"I am on top of the world!\",\n",
    "    \"I just had a terrible day at work.\",\n",
    "    \"I'm worried about my exam.\",\n",
    "    \"That book was thrilling!\",\n",
    "    \"I'm feeling adventurous.\",\n",
    "    \"I'm feeling so lazy today.\",\n",
    "    \"That was a scary movie.\",\n",
    "    \"I am grateful for my friends.\",\n",
    "    \"The party was a blast!\",\n",
    "    \"That test was really hard.\",\n",
    "    \"I feel loved.\",\n",
    "    \"I feel so rejected.\",\n",
    "    \"I'm bursting with joy.\",\n",
    "    \"I'm disgusted by the trash.\",\n",
    "    \"That was a stressful situation.\",\n",
    "    \"I'm so proud of my team.\",\n",
    "    \"I'm amazed by the view.\",\n",
    "    \"That song was touching.\",\n",
    "    \"I feel so lonely.\",\n",
    "    \"I'm feeling nostalgic.\",\n",
    "    \"The race was intense.\",\n",
    "    \"That was an awkward conversation.\",\n",
    "    \"I feel inspired.\",\n",
    "    \"I'm feeling playful.\",\n",
    "    \"I'm feeling ambitious.\",\n",
    "    \"I'm feeling doubtful.\",\n",
    "    \"That was a surprising result.\",\n",
    "    \"I'm feeling content.\",\n",
    "    \"I'm so disappointed.\",\n",
    "    \"I'm feeling hopeful.\",\n",
    "    \"That was a frustrating experience.\",\n",
    "    \"I feel so appreciated.\",\n",
    "    \"I'm confused.\",\n",
    "    \"I'm feeling motivated.\",\n",
    "    \"I'm feeling pessimistic.\",\n",
    "    \"I'm feeling apathetic.\",\n",
    "    \"That was an impressive performance.\",\n",
    "    \"I'm curious about the result.\",\n",
    "    \"I'm feeling so relaxed.\",\n",
    "    \"I'm feeling agitated.\",\n",
    "    \"That was a depressing story.\",\n",
    "    \"I'm feeling optimistic.\",\n",
    "    \"I feel so empowered.\",\n",
    "    \"I'm feeling ashamed.\",\n",
    "    \"I'm feeling energized.\",\n",
    "    \"I'm feeling apprehensive.\",\n",
    "    \"I'm feeling delighted.\",\n",
    "    \"I'm feeling guilty.\",\n",
    "    \"That was a challenging puzzle.\",\n",
    "    \"I'm feeling so refreshed.\",\n",
    "    \"I'm feeling overwhelmed.\",\n",
    "    \"I'm feeling serene.\",\n",
    "    \"I'm feeling vulnerable.\",\n",
    "    \"That was a fascinating lecture.\",\n",
    "    \"I'm feeling proud.\",\n",
    "    \"I'm feeling humiliated.\",\n",
    "    \"I'm feeling so exhilarated.\",\n",
    "    \"I'm feeling regretful.\",\n",
    "    \"I'm feeling contented.\",\n",
    "    \"I'm feeling restless.\",\n",
    "    \"That was an enchanting evening.\",\n",
    "    \"I'm feeling tranquil.\",\n",
    "    \"I'm feeling tormented.\",\n",
    "    \"I'm feeling triumphant.\",\n",
    "    \"I'm feeling desolate.\",\n",
    "    \"I'm feeling blissful.\",\n",
    "    \"I'm feeling distressed.\",\n",
    "    \"I'm feeling jubilant.\",\n",
    "    \"I'm feeling woeful.\",\n",
    "    \"I'm feeling exuberant.\",\n",
    "    \"I'm feeling despondent.\",\n",
    "    \"I'm feeling ecstatic.\",\n",
    "    \"I'm feeling inconsolable.\",\n",
    "    \"I'm feeling rapturous.\",\n",
    "    \"I'm feeling forlorn.\",\n",
    "    \"I'm feeling exhilarated.\",\n",
    "    \"I'm feeling downhearted.\"\n",
    "]\n",
    "\n",
    "for sentence in sentences[:20]:\n",
    "    emojis = engine.process_query_tf_idf(sentence, indexer._clean_text)\n",
    "    print(f\"{sentence} {emojis}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just had the best coffee at @CafeLuv #CoffeeLover 🎀, 🎾, 🌚, 👌🏻, 😩👌\n",
      "Getting ready for a Friday night out with the girls! 💃 #FridayFeeling 🙌🙌, 🤑, 🍭, 🙌🏻🙌🏻🙌🏻, 🤝\n",
      "Who else is excited for the new Avengers movie? 🍿 #MarvelFan 🤙🏼, 🔑, 🖕🏽, 🤔, ❗\n",
      "Can't believe how beautiful the sunset was today. 🌅 #NaturePhotography 🐦, ☀️, 🤙🏻, 🎉, 😍\n",
      "Dinner at my favorite sushi place 🍣 #Foodie 👅, 🤙🏻, 👀, 🙄, 🚌\n",
      "Throwback to my trip to Paris last summer 🗼 #TravelDiaries 🍞, 💘, ⁉️, ☺️, 😎💦\n",
      "Feeling so blessed to have such amazing people in my life 🥰 #Blessed ✨, 🙏, 🍩, 🙏🏼, 🙏🏻🙏🏻🙏🏻\n",
      "Workout done for the day! 💪 #FitnessGoals 😍🙌, 🍑, ☝️, 👐🏽, 🙏🏾🙏🏾🙏🏾\n",
      "I could spend all day reading at this quiet little bookstore 📚 #BookWorm 👏🏼, 👇🏻, 🐥, 👇👇, 💕\n",
      "Had an awesome time at the concert last night! 🎤 #LiveMusic 😔, 🍃, 🌚, 💊, 😈\n",
      "I can assist you with booking a flight ✈️ #ChatBot 👉, 🙏🏼, 😍❤️, 😻, 💚\n",
      "What can I help you find today? 🔍 #CustomerService 😔✌️, 👔, ✔️, 🙏🏼✨, 😁\n",
      "Processing your request now... ⏳ #AI 😫, 🙏🏽, 👇👇, 🍆, 😔\n",
      "Your order has been placed! 🛍️ #ShoppingBot 🌳, 🤔, 🙌🏽🙌🏽, 💌, 💫\n",
      "The weather in New York today is sunny with a high of 75 degrees 🌞 #WeatherBot 😍, ✌️, 😎, 🎧, 😑\n",
      "Directing you to a customer service representative now 📞 #HelpBot 😃, 🙌🏼, 🙏🙏, 💜, 👇\n",
      "That information is not currently available. Can I assist with anything else? ❓ #InfoBot 👏🏻, 👏, 👍🏻, 🔥, 🍃\n",
      "You have 3 new notifications 📬 #ReminderBot 😭✋🏻, 💕, 🌻, 👑, 🌪️\n",
      "You successfully completed your daily step goal! 🏃‍♀️ #HealthBot 🙌🏼, 👑, 😃, 👅, 👌\n",
      "Your package has been shipped and is on its way 📦 #DeliveryUpdate 👜, ✈️, 📦, 🔊, 👏\n"
     ]
    }
   ],
   "source": [
    "social_media_sentences = [\n",
    "    \"Just had the best coffee at @CafeLuv ☕️ #CoffeeLover\",\n",
    "    \"Getting ready for a Friday night out with the girls! 💃 #FridayFeeling\",\n",
    "    \"Who else is excited for the new Avengers movie? 🍿 #MarvelFan\",\n",
    "    \"Can't believe how beautiful the sunset was today. 🌅 #NaturePhotography\",\n",
    "    \"Dinner at my favorite sushi place 🍣 #Foodie\",\n",
    "    \"Throwback to my trip to Paris last summer 🗼 #TravelDiaries\",\n",
    "    \"Feeling so blessed to have such amazing people in my life 🥰 #Blessed\",\n",
    "    \"Workout done for the day! 💪 #FitnessGoals\",\n",
    "    \"I could spend all day reading at this quiet little bookstore 📚 #BookWorm\",\n",
    "    \"Had an awesome time at the concert last night! 🎤 #LiveMusic\",\n",
    "    \"I can assist you with booking a flight ✈️ #ChatBot\",\n",
    "    \"What can I help you find today? 🔍 #CustomerService\",\n",
    "    \"Processing your request now... ⏳ #AI\",\n",
    "    \"Your order has been placed! 🛍️ #ShoppingBot\",\n",
    "    \"The weather in New York today is sunny with a high of 75 degrees 🌞 #WeatherBot\",\n",
    "    \"Directing you to a customer service representative now 📞 #HelpBot\",\n",
    "    \"That information is not currently available. Can I assist with anything else? ❓ #InfoBot\",\n",
    "    \"You have 3 new notifications 📬 #ReminderBot\",\n",
    "    \"You successfully completed your daily step goal! 🏃‍♀️ #HealthBot\",\n",
    "    \"Your package has been shipped and is on its way 📦 #DeliveryUpdate\"\n",
    "]\n",
    "\n",
    "for sentence in social_media_sentences:\n",
    "    emojis = engine.process_query_tf_idf(sentence, indexer._clean_text)\n",
    "    print(f\"{sentence} {emojis}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
