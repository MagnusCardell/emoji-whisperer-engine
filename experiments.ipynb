{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset length:  10017\n",
      "   Sl no                                             Tweets     Search key  \\\n",
      "0      1   #1: @fe ed \"RT @MirayaDizon1: Time is ticking...  happy moments   \n",
      "1      2   #2: @ËìÆËä± &„ÅØ„Åô„Åã ed \"RT @ninjaryugo: ÔºÉ„Ç≥„Éä„É¢„É≥„ÅÆÊó• „Å†„Åù„ÅÜ„Åß...  happy moments   \n",
      "2      3   #3: @Ris ‚ô° ed \"Happy birthday to one smokin h...  happy moments   \n",
      "3      4   #4: @ÏõîÏõî [ÏîçÏØ¥ÏÇ¨ÎûëÎ°úÎ¥á] jwinnie is the best, cheer u...  happy moments   \n",
      "4      5   #5: @Madhurima wth u vc‚ô• ed \"Good morning dea...  happy moments   \n",
      "5      6   #6: @Jeinal√≠s Ramos ed \"Happy moments üôèüèΩ http...  happy moments   \n",
      "6      7   #7: @Eric Rogers ed \"@CaitlinUnruh The movie ...  happy moments   \n",
      "7      8   #8: @Yanny Sandal ed \"I don‚Äôt give two shits ...  happy moments   \n",
      "8      9   #9: @daynada ed \"my beautiful barbie bride an...  happy moments   \n",
      "9     10   #10: @√üüå™ ed \"Someone Great has been one of th...  happy moments   \n",
      "\n",
      "  Feeling  \n",
      "0   happy  \n",
      "1   happy  \n",
      "2   happy  \n",
      "3   happy  \n",
      "4   happy  \n",
      "5   happy  \n",
      "6   happy  \n",
      "7   happy  \n",
      "8   happy  \n",
      "9   happy  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/data.csv')\n",
    "print(\"dataset length: \", len(df))\n",
    "print(df[:10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a search engine for emojis\n",
    "\n",
    "1. Index the corpus\n",
    "\n",
    "term - token\n",
    "\n",
    "term - emoji index. A sparse matrix with true/false if emoji appears with term\n",
    "inverted index - dictionary of terms, and a list of their appearances (emojis)\n",
    "\n",
    "Building index:\n",
    "1. collect documents (sentences with emojis)\n",
    "2. tokenize the documents\n",
    "3. preprocess the tokens. lowercase, cleanup, english\n",
    "4. Index documents with inverted index\n",
    "\n",
    "Each emoji has unique ID\n",
    "Maintain dictionary and postings\n",
    "dictionary - emoji and pointer to document its from\n",
    "postings - inverted index [emoji, frequency in doc, [docID1, docID2]]\n",
    "\n",
    "\n",
    "Boolean query Happy AND Sad\n",
    "Answer set rank emojis that has both happy and sad, otherwise, happy then sad, depending on frequency. \n",
    "\n",
    "Tokenization\n",
    "- lowercase might be bad for emojis because we need to keep names apart from words (General Motors)\n",
    "- stemming and lemmatization - Porter algorithm\n",
    "\n",
    "Intersection algorithm for Happy and Sad is O(n+m) where n and m are number of occurrences \n",
    "\n",
    "Tolerant retrieval\n",
    "Wildcard searches like re*val would need to use re AND val. for those searches, \n",
    "k-gram index woudl help\n",
    "phonetic correction\n",
    "lehvenstein distance\n",
    "\n",
    "\n",
    "Index compression\n",
    "Possibly 75% less storage\n",
    "Allow use of caching frequently used terms and \n",
    "Rule of 30 - the 30 most common words account for 30% of the tokens in text. \n",
    "In the postings list, the term is the most space needed. Instead of using the emoji, use a pointer to the emoji\n",
    "\n",
    "\n",
    "Scoring, term weighting, vector space model \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
